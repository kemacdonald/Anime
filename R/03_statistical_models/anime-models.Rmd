---
title: "Anime Statisical Models"
author: "Kyle MacDonald"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F)
```

```{r load_packages, include = FALSE}
library(rstanarm); library(car); library(tidyverse)

# Set the number of cores to the number of cores on your computer.
options(mc.cores = parallel::detectCores())
```

Load trial-level data.

```{r}
d <- read_csv(file = "../../data/03_summary_tables/anime_trial_level.csv")
```

## Experiment 1

### Reaction Time

Compare RTs on familiar cue trials as a function of cue type. We use Bayesian linear mixed effects models because we are interested in providing an estimate of the strength of evidence for the hypothesis of *no difference* in RT and Accuracy across the different cue types.

We also log transform Reaction Times (RT) to be more suitable for modeling on a linear scale.

```{r}
d_e1_rt <- d %>% filter(experiment == "e1",
                              Response == "D", 
                              trial_type == "familiar",
                              RT >= 300, RT <= 2500,
                              GoodRT == T,
                              GoodFirstGap == T,
                              GoodLongestGap == T) %>% 
  mutate(log_rt = log(RT))
```

Fit the varying intercepts and slopes model.

```{r}
m_bglmer <- stan_glmer(
  log_rt ~ cue_type + (clean_target_img | Sub.Num), # specify model formula the same way as in glmer 
  family = gaussian(), # specify type of model
  data = d_e1_rt,
  prior = normal(0, 2), # prior on model coefs (Does not include coefficients that vary by group in a multilevel model)
  prior_intercept = normal(0, 5), # prior on intercept after centering predictors
  prior_covariance = decov(regularization = 2), # prior on Covariance matrices for mixed effects model
  chains = 4
)
```

Note that we get some error message, but this should nbot affect results per [this](https://github.com/stan-dev/rstanarm/issues/202) github issue.

Extract the samples from the model obect.

```{r}
# Get a dataframe: One row per posterior sample
d_post_rt_e1 <- m_bglmer %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(name = `(Intercept)`) %>% 
  select(name, cue_typeonomatopoeic, cue_typevocalization) %>% 
  mutate(cue_typeonomatopoeic = name + cue_typeonomatopoeic,
         cue_typevocalization = name + cue_typevocalization) %>% 
  gather(key = cue_type, value = param_est) %>% 
  mutate(cue_type = case_when(
    cue_type == "cue_typeonomatopoeic" ~ "onomatopoeia", 
    cue_type == "cue_typevocalization" ~ "vocalization",
    TRUE ~ "name"
  ),
  rt_scale_param = exp(param_est))
```

### Accuracy

Note that we use the empirical logit to transform proportion looking scores to be more suitable for modeling on the linear scale. 

```{r}
d_e1_acc_fam <- d %>% 
  filter(experiment == "e1") %>% 
  mutate(emp_logit_acc = car::logit(m_prop_looking))
```

Fit accuracy model to compare proportion looking for familiar cues. 

```{r}
m_acc_e1 <- stan_glmer(
  emp_logit_acc ~ cue_type + trial_type + (clean_target_img | Sub.Num), # specify model formula the same way as in glmer 
  family = gaussian(), # specify type of model
  data = d_e1_acc_fam,
  prior = normal(0, 2), # prior on model coefs (Does not include coefficients that vary by group in a multilevel model)
  prior_intercept = normal(0, 5), # prior on intercept after centering predictors
  prior_covariance = decov(regularization = 2), # prior on Covariance matrices for mixed effects model
  chains = 4
)
```

Let's first extract the samples from the model obect.

```{r}
# make function to convert logit back to probability 
logit_to_prob <- function(logit) {
  odds <- exp(logit)
  odds / (1 + odds)
}
```

 Get a dataframe: One row per posterior sample

```{r}
d_post_acc_e1 <- m_acc_e1 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  rename(intercept = `(Intercept)`) %>% 
  select(intercept, cue_typeonomatopoeic, cue_typevocalization, trial_typefamiliar) %>% 
  mutate(cue_typeonomatopoeic_familiar = intercept + cue_typeonomatopoeic + trial_typefamiliar,
         cue_typevocalization_familiar = intercept + cue_typevocalization + trial_typefamiliar,
         cue_typename_familiar = intercept + trial_typefamiliar) %>% 
  rename(intercept_novel = intercept, 
         cue_typeonomatopoeic_novel = cue_typeonomatopoeic, 
         cue_typevocalization_novel = cue_typevocalization) %>% 
  mutate(cue_typeonomatopoeic_novel = intercept_novel + cue_typeonomatopoeic_novel,
          cue_typevocalization_novel = intercept_novel + cue_typevocalization_novel) %>% 
  select(-trial_typefamiliar) %>% 
  gather(key = cue_type, value = param_estimate) %>% 
  mutate(cue_type = str_replace(cue_type, pattern = "cue_type", "")) %>% 
  separate(cue_type, sep = "_", into = c("cue_type", "trial_type")) %>% 
  mutate(cue_type = ifelse(cue_type == "intercept", "name", cue_type),
         acc_prob_scale = logit_to_prob(param_estimate))
```

## Experiment 2

### RT

```{r}
d_e2_rt <- d %>% filter(experiment == "e2",
                              Response == "D", 
                              RT >= 300, RT <= 2500,
                              GoodRT == T,
                              GoodFirstGap == T,
                              GoodLongestGap == T) %>% 
  mutate(log_rt = log(RT))
```

Fit the varying intercepts and slopes model.

```{r}
m_rt_e2 <- stan_glmer(
  log_rt ~ trial_type + (clean_target_img | Sub.Num), # specify model formula the same way as in glmer 
  family = gaussian(), # specify type of model
  data = d_e2_rt,
  prior = normal(0, 2), # prior on model coefs (Does not include coefficients that vary by group in a multilevel model)
  prior_intercept = normal(0, 5), # prior on intercept after centering predictors
  prior_covariance = decov(regularization = 2), # prior on Covariance matrices for mixed effects model
  chains = 4
)
```

Extract the samples from the model obect.

```{r}
# Get a dataframe: One row per posterior sample
d_post_rt_e2 <- m_rt_e2 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  rename(intercept = `(Intercept)`) %>% 
  select(intercept, trial_typefamiliar, trial_typeretention) %>% 
  mutate(trial_typefamiliar = intercept + trial_typefamiliar,
         trial_typeretention = intercept + trial_typeretention) %>% 
  rename(disambiguation = intercept, 
         familiar = trial_typefamiliar,
         retention = trial_typeretention) %>% 
  gather(key = trial_type, value = param_estimate) %>% 
  mutate(rt_scale_param = exp(param_estimate))
```

### Accuracy

```{r}
d_e2_acc_fam <- d %>% 
  filter(experiment == "e2") %>% 
  mutate(emp_logit_acc = car::logit(m_prop_looking))
```

Fit accuracy model to compare proportion looking for familiar cues. 

```{r}
m_acc_e2 <- stan_glmer(
  emp_logit_acc ~ trial_type + (clean_target_img | Sub.Num), # specify model formula the same way as in glmer 
  family = gaussian(), # specify type of model
  data = d_e2_acc_fam,
  prior = normal(0, 2), # prior on model coefs (Does not include coefficients that vary by group in a multilevel model)
  prior_intercept = normal(0, 5), # prior on intercept after centering predictors
  prior_covariance = decov(regularization = 2), # prior on Covariance matrices for mixed effects model
  chains = 4
)
```

Get a dataframe: One row per posterior sample

```{r}
d_post_acc_e2 <- m_acc_e2 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  rename(intercept = `(Intercept)`) %>% 
  select(intercept, trial_typefamiliar, trial_typeretention) %>% 
  mutate(trial_typefamiliar = intercept + trial_typefamiliar,
         trial_typeretention = intercept + trial_typeretention) %>% 
  rename(disambiguation = intercept, 
         familiar = trial_typefamiliar,
         retention = trial_typeretention) %>% 
  gather(key = trial_type, value = param_estimate) %>% 
  mutate(acc_prob_scale = logit_to_prob(param_estimate))
```

## Save posterior model estimates

```{r}
posteriors <- list(rt_e1 = d_post_rt_e1,
                   acc_e1 = d_post_acc_e1,
                   acc_e2 = d_post_acc_e2,
                   rt_e2 = d_post_rt_e2)

saveRDS(posteriors, file = "../../data/03_summary_tables/anime-posterior-samples.rds")

beepr::beep(sound = "fanfare")
```
